{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2526e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project root: /home/viktoriia/Documents/ML/project-25-2-scrum-team-data\n",
      "Added to sys.path: /home/viktoriia/Documents/ML/project-25-2-scrum-team-data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root from the notebooks/ folder\n",
    "project_root = Path.cwd().parent\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(\"Added to sys.path:\", project_root)\n",
    "\n",
    "# Just to check:\n",
    "import vector_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d58877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Chroma DB from /home/viktoriia/Documents/ML/project-25-2-scrum-team-data/chroma_db ...\n",
      "Vectorstore loaded successfully.\n",
      "Document count: 6401\n",
      "Vectorstore ready, example document count might be available in notebooks, but at least this call should not crash.\n"
     ]
    }
   ],
   "source": [
    "from vector_pipeline.ingestion import build_or_load_vectorstore\n",
    "\n",
    "vs = build_or_load_vectorstore()\n",
    "print(\"Vectorstore ready, example document count might be available in notebooks, \"\n",
    "      \"but at least this call should not crash.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d1659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Chroma DB from /home/viktoriia/Documents/ML/project-25-2-scrum-team-data/chroma_db ...\n",
      "Vectorstore loaded successfully.\n",
      "Document count: 6401\n"
     ]
    }
   ],
   "source": [
    "from vector_pipeline.api_wrapper import answer_single_turn\n",
    "\n",
    "result = answer_single_turn(\"Recommend some cheap black running shoes\")\n",
    "print(\"Answer:\\n\", result[\"answer\"][:500])\n",
    "\n",
    "print(\"\\nNumber of retrieved chunks:\", len(result[\"retrieved\"]))\n",
    "print(\"First snippet:\\n\", result[\"retrieved\"][0][\"snippet\"][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_pipeline.api_wrapper import (\n",
    "    run_chat_langgraph_session,\n",
    "    run_chat_langgraph_stateless,\n",
    ")\n",
    "\n",
    "print(\"LangGraph wrappers imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33426442",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"test-session-001\"\n",
    "\n",
    "q1 = \"I want wireless headphones with long battery life.\"\n",
    "res1 = run_chat_langgraph_session(q1, session_id=session_id)\n",
    "\n",
    "print(\"Turn 1 - answer:\\n\", res1[\"answer\"][:400])\n",
    "print(\"Turn 1 - retrieved chunks:\", len(res1[\"retrieved\"]))\n",
    "\n",
    "q2 = \"Can you suggest something cheaper from the same category?\"\n",
    "res2 = run_chat_langgraph_session(q2, session_id=session_id)\n",
    "\n",
    "print(\"\\nTurn 2 - answer:\\n\", res2[\"answer\"][:400])\n",
    "print(\"Turn 2 - retrieved chunks:\", len(res2[\"retrieved\"]))\n",
    "\n",
    "print(\"\\nFull message history (roles):\")\n",
    "for m in res2[\"messages\"]:\n",
    "    print(\"-\", m[\"role\"], \":\", m[\"content\"][:80].replace(\"\\n\", \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Show me running shoes in red.\"}\n",
    "]\n",
    "\n",
    "res = run_chat_langgraph_stateless(messages)\n",
    "\n",
    "print(\"Stateless answer:\\n\", res[\"answer\"][:400])\n",
    "print(\"History length:\", len(res[\"messages\"]))\n",
    "print(\"Retrieved chunks:\", len(res[\"retrieved\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69d279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29a9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f72d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
